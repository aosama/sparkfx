{"paragraphs":[{"text":"val dataDir =  \"s3://ahmedexperiments\"\n\nspark.conf.set(\"spark.sql.shuffle.partitions\",200)\nspark.conf.set(\"spark.default.parallelism\",200)\n","user":"anonymous","dateUpdated":"2020-05-03T10:10:18+0000","config":{"runOnSelectionChange":true,"title":false,"checkEmpty":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\u001b[1m\u001b[34mdataDir\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = s3://ahmedexperiments\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1588498554277_1252810415","id":"paragraph_1588498554277_1252810415","dateCreated":"2020-05-03T09:35:54+0000","dateStarted":"2020-05-03T10:10:18+0000","dateFinished":"2020-05-03T10:10:36+0000","status":"FINISHED","focus":true,"$$hashKey":"object:5509"},{"user":"anonymous","config":{"runOnSelectionChange":true,"title":false,"checkEmpty":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1588500400914_-393217226","id":"paragraph_1588500400914_-393217226","dateCreated":"2020-05-03T10:06:40+0000","status":"FINISHED","focus":true,"$$hashKey":"object:6211","text":"spark.conf.get(\"spark.sql.shuffle.partitions\")","dateUpdated":"2020-05-03T10:10:19+0000","dateFinished":"2020-05-03T10:10:36+0000","dateStarted":"2020-05-03T10:10:20+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\u001b[1m\u001b[34mres2\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = 200\n"}]}},{"text":"\nimport java.math.{BigDecimal, BigInteger}\nimport java.security.{MessageDigest, NoSuchAlgorithmException}\nimport org.apache.spark.sql.SaveMode\n\nimport org.apache.commons.codec.binary.Base32\nimport org.apache.spark.sql.functions.udf\n\nobject Helpers extends Serializable {\n\n  val getShaBinaryStringFromLongUdf = udf[String , Long](getShaBinaryStringFromLong)\n  val scanStringUdf = udf[List[String] , String,Int](scanString)\n  val getLongFromBinaryStringUdf = udf[Long , String](getLongFromBinaryString)\n  val parseLongUdf = udf[Long , String ,Int](parseLong)\n  val countOnesUdf = udf[Int,String](countOnes)\n\n  def getLongFromBinaryString(string :String) :Long = {\n    new BigInteger(string,2).longValue()\n  }\n\n  def scanString(s :String , n :Int) :List[String] = {\n    var lst = List[String]()\n    for (i <- 0 to s.length - n)\n    {\n      val ss = s.substring(i , i+n)\n      lst :+= ss\n    }\n    lst\n  }\n\n  @throws[NoSuchAlgorithmException]\n  def getShaBinaryStringFromBinaryString(binaryAsString: String) = {\n    val bytes = getShaBytesFromBinaryString(binaryAsString)\n    val stringFromByteArray = getStringFromByteArray(bytes)\n    stringFromByteArray\n  }\n\n  @throws[NoSuchAlgorithmException]\n  def getShaBytesFromBinaryString(binaryString: String) = {\n    val digest = MessageDigest.getInstance(\"SHA-256\")\n    val shaByteArray = digest.digest(getByteArrayFromBinaryString(binaryString))\n    shaByteArray\n  }\n\n  def getByteArrayFromBinaryString(binaryString: String) = {\n    require(binaryString.length == 256)\n    new BigInteger(binaryString,2).toByteArray\n  }\n\n  def getStringFromByteArray(byteArray: Array[Byte]) = {\n    val sb = new StringBuilder(\"\")\n    for (b <- byteArray) {\n      val s1 = String.format(\"%8s\", Integer.toBinaryString(b & 0xFF)).replace(' ', '0')\n      sb.append(s1)\n    }\n    sb.toString\n  }\n\n  @throws[NoSuchAlgorithmException]\n  def getShaBinaryStringFromLong(longValue: Long) = {\n    val digest = MessageDigest.getInstance(\"SHA-256\")\n    val shaByteArray = digest.digest(BigInt(longValue).toByteArray)\n    val stringFromByteArray = getStringFromByteArray(shaByteArray)\n    stringFromByteArray\n  }\n\n  def encodeBase32(binaryAsStringinput: String) :String = {\n    val byteArrayFromBinaryString: Array[Byte] = getByteArrayFromBinaryString(binaryAsStringinput)\n    encodeBase32(byteArrayFromBinaryString)\n  }\n\n  def encodeBase32(bytes: Array[Byte]) = {\n    val b32 = new Base32\n    val encodeAsString = b32.encodeAsString(bytes)\n    encodeAsString\n  }\n\n  def countOnes(str: String) :Int = {\n    str.toCharArray.count(x => x.equals('1'))\n  }\n\n  @throws[NoSuchAlgorithmException]\n  def getShaBigIntegerFromLong(longValue: Long) = {\n    val shaBytesFromLong = getShaBytesFromLong(longValue)\n    val bigIntegerFromByteArray = getBigIntegerFromByteArray(shaBytesFromLong)\n    bigIntegerFromByteArray\n  }\n\n  @throws[NoSuchAlgorithmException]\n  def getShaBytesFromLong(longValue: Long) = {\n    val digest = MessageDigest.getInstance(\"SHA-256\")\n    val shaByteArray = digest.digest(BigInt(longValue).toByteArray)\n    shaByteArray\n  }\n\n  def getBigIntegerFromByteArray(bytes: Array[Byte]) = {\n    val bi = new BigInteger(1, bytes)\n    bi\n  }\n\n  @throws[NoSuchAlgorithmException]\n  def getShaBigDecimalFromLong(value: Long) = {\n    val shaBytesFromLong = getShaBytesFromLong(value)\n    val bigIntegerFromByteArray = getBigIntegerFromByteArray(shaBytesFromLong)\n    val bigDecimalFromBigInteger = getBigDecimalFromBigInteger(bigIntegerFromByteArray)\n    bigDecimalFromBigInteger\n  }\n\n  def getBigDecimalFromBigInteger(bigInteger: BigInteger) = {\n    val bd = new BigDecimal(bigInteger)\n    bd\n  }\n\n  def getBinaryString256FromLong(longValue: Long) =\n    {\n      longValue.toBinaryString.padTo(256,'0').reverse\n    }\n\n  def generateRange(start :BigInt , finish :BigInt): Seq[BigInt] =\n  {\n    val x: Seq[BigInt] =  (start to finish)\n    return x\n  }\n\n  def parseLong(s :String , base :Int) : Long = {\n    new BigInteger(s,base).longValue()\n  }\n\n\n}","user":"anonymous","dateUpdated":"2020-05-03T10:10:50+0000","config":{"runOnSelectionChange":true,"title":false,"checkEmpty":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.math.{BigDecimal, BigInteger}\nimport java.security.{MessageDigest, NoSuchAlgorithmException}\nimport org.apache.spark.sql.SaveMode\nimport org.apache.commons.codec.binary.Base32\nimport org.apache.spark.sql.functions.udf\ndefined object Helpers\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1588498385762_-1003074997","id":"paragraph_1588498385762_-1003074997","dateCreated":"2020-05-03T09:33:05+0000","dateStarted":"2020-05-03T10:10:50+0000","dateFinished":"2020-05-03T10:10:51+0000","status":"FINISHED","$$hashKey":"object:5510"},{"text":"\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions.{col, udf, _}\n\nimport scala.collection.immutable\n\nimport java.util\n\nobject BitSetUtils {\n\n  implicit def bool2int(b:Boolean) = if (b) 1 else 0\n\n  implicit class BitSetImprovements(val bs :util.BitSet)\n  {\n    def printBitSet() :Unit ={\n      var sb = new StringBuilder()\n      (0 to bs.length()).foreach(b => sb.append(bs.get(b).toInt) )\n      println(sb.toString())\n    }\n  }\n\n}\n\n\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions.{col, udf, _}\n\nimport scala.collection.immutable\n\nobject SparkBinaryGenerator  {\n\n  import BitSetUtils._\n\n  lazy val patternMap = (0 to numPossiblePatterns - 1).map(p => {\n    val searchPattern = p.toBinaryString.reverse.padTo(numBitsInPattern, '0').reverse\n    p -> searchPattern\n  }).toMap\n  val orStringUdf = udf[String, Seq[String]](orString)\n  val shaBinaryStringFromBinaryStringUdf = udf[String, String](Helpers.getShaBinaryStringFromBinaryString)\n  val twoToThePower0to255Seq: Seq[String] = (0 to 255)\n    .map(x => BigInt(\"2\").pow(x))\n    .map(x => x.toString(2).reverse.padTo(256, '0').reverse)\n  var numBitsInPattern = 13\n\n  def generateTruthTableString(nBits: Int): DataFrame = {\n    val df = spark.range(0, Math.pow(2, nBits).toLong,1,200).toDF(\"inputlong\")\n    val longToBinary = udf((l: Long) => l.toBinaryString.reverse.padTo(nBits, '0').reverse)\n    df.withColumn(\"truthtable\", longToBinary('inputlong)).drop('inputlong)\n  }\n\n  def generateTruthTableLong(nBits: Int): DataFrame = {\n    spark.range(0, Math.pow(2, nBits).toLong).toDF(\"truthtable\")\n  }\n\n  def generateShaColumn(df: DataFrame): DataFrame = {\n    df.withColumn(\"shaString\", shaBinaryStringFromBinaryStringUdf('inputBinary))\n  }\n\n  def generateScanStringColumns(inputDf: DataFrame, maxLength: Int, scanLength: Int): DataFrame = {\n    var df = inputDf\n    for (i <- 0 to maxLength - scanLength + 1) {\n      df = df.withColumn(\"s\" + i, 'shaString.substr(i, scanLength))\n    }\n    df\n  }\n\n  def generateScanLongColumns(inputDf: DataFrame, maxLength: Int, scanLength: Int): DataFrame = {\n    var df = inputDf\n\n    for (i <- 0 to maxLength - scanLength + 1) {\n      df = df.withColumn(\"l\" + i, Helpers.parseLongUdf('shaString.substr(i, scanLength), lit(scanLength)))\n    }\n    df\n  }\n\n  def generateDecimalValuesFor32BitSequencesOfSha(df: DataFrame): DataFrame = {\n    var dfTemp = df.withColumn(\"scannedInputBinary\", Helpers.scanStringUdf('shaString, lit(32)))\n\n    (1 to 32).foreach(c => {\n      dfTemp = dfTemp\n        .withColumn(\"seq\" + c + \"temp\", 'scannedInputBinary.getItem(c))\n        .withColumn(\"seq\" + c,\n          Helpers.getLongFromBinaryStringUdf(col(\"seq\" + c + \"temp\")))\n        .drop(\"seq\" + c + \"temp\")\n    })\n\n    dfTemp.drop(\"scannedInputBinary\")\n  }\n\n  def generateSearchPatterns(df: DataFrame): DataFrame = {\n    df.rdd.flatMap(row => {\n      val inputBinary: String = row.getString(0)\n      val shaString = row.getString(1)\n      var resultSequence = List[(String, String, String, String)]()\n\n      //pattern to search for\n      (0 to numPossiblePatterns - 1).foreach(p => {\n        //val searchPattern = p.toBinaryString.reverse.padTo(numBitsInPattern, '0').reverse\n        val searchPattern = patternMap.get(p).get\n        val patternExists = shaString.contains(searchPattern).toInt.toString\n        resultSequence :+= ((inputBinary, shaString, searchPattern, patternExists))\n      })\n      resultSequence\n    }).toDF(\"inputBinary\", \"shaString\", \"searchPattern\", \"exists\")\n  }\n\n  def numPossiblePatterns = Math.pow(2, numBitsInPattern).toInt\n\n  def generateNbits(numBitsSet: Int, patternLength: Int, distinct: Boolean): DataFrame = {\n    var colSeqString = Seq[String]()\n    for (i <- 1 to numBitsSet) {\n      colSeqString :+= \"bit\" + i\n    }\n    val colSeq = colSeqString.map(x => col(x))\n\n    val df = spark.range(0, 256).toDF(\"bit1\").cache()\n\n    //initializing any value\n    var df2 = df\n    //create N columns where N = numBitsSet\n    for (i <- 2 to numBitsSet) {\n      df2 = df2.crossJoin(df.withColumnRenamed(\"bit1\", \"bit\" + i))\n    }\n\n    //removing entrie with unique values not equal to numBitSet\n    df2 = df2.filter(row => {\n      val valuesMap: Map[String, Long] = row.getValuesMap[Long](colSeqString)\n      val bitLocationArr: immutable.Iterable[Long] = valuesMap.map({ case (k, v) => v })\n      //if all bit locations are not unique then skip\n      if (bitLocationArr.toSet.size == numBitsSet) {\n        true\n      }\n      else {\n        false\n      }\n    })\n\n    //do a logic or operation for the N columns\n    df2 = df2.map(row => {\n      val valuesMap: Map[String, Long] = row.getValuesMap[Long](colSeqString)\n      val bitLocationArr: immutable.Iterable[Long] = valuesMap.map({ case (k, v) => v })\n      var tmpString = \"0\" * 256\n      bitLocationArr.map(x => x.toInt).map(x => tmpString = tmpString.updated(255 - x, '1'))\n      tmpString\n    }).toDF(\"truthTable\")\n\n    if (distinct) {\n      df2.distinct()\n    } else {\n      df2\n    }\n\n  }\n\n  def generate1Bits(): DataFrame = {\n    return twoToThePower0to255Seq.toDF(\"inputBinary\")\n  }\n\n  def generate2Bits(): DataFrame = {\n    val df = twoToThePower0to255Seq.toDF(\"bit1\")\n    val df2 = df.crossJoin(df.withColumnRenamed(\"bit1\", \"bit2\"))\n      .withColumn(\"inputBinary\", orStringUdf('bit1, 'bit2))\n      .select('inputBinary)\n      .filter('inputBinary.notEqual(\"duplicate\"))\n      .distinct()\n    df2\n  }\n\n  def generateRandomNbitsOfKbits(n: Int, k: Int, limit: Long,\n                                 alwaysSetBitLocation: Option[Int] = Option.empty,\n                                 valueForBitLocation: Option[Int] = Option.empty): DataFrame = {\n\n    val df: DataFrame = spark.range(0, limit).toDF(\"id\")\n    val seed = 91234\n\n    df.map(row => {\n      val rowid = row.getLong(0)\n      val rand = new scala.util.Random(rowid)\n      var inputBinary: String = \"0\" * k\n\n      if (alwaysSetBitLocation.nonEmpty) {\n        require(valueForBitLocation.nonEmpty)\n        inputBinary = inputBinary.updated(k -alwaysSetBitLocation.get.toInt, valueForBitLocation.get.toString.charAt(0))\n      }\n\n      while (inputBinary.count(_ == '1') < n) {\n        val bit = rand.nextInt(k)\n        inputBinary = inputBinary.updated(bit, '1')\n      }\n\n      inputBinary\n    }).toDF(\"inputBinary\")\n//      .withColumn(\"countones\", Helpers.countOnesUdf('inputBinary))\n//      .filter('countones === n).drop(\"countones\")\n  }\n\n  def orString(inputs: String*): String = {\n    val sbResult = new StringBuilder(\"0\" * 256)\n    for (i <- 0 to inputs.size - 1) {\n      for (j <- 0 to sbResult.toString().length - 1) {\n        val tempBit1 = sbResult.toString().charAt(j).asDigit\n        val tempBit2 = inputs(i).charAt(j).asDigit\n        val orResult = (tempBit1 == 1 || tempBit2 == 1).toInt\n        sbResult.setCharAt(j, orResult.toString.charAt(0))\n      }\n    }\n    sbResult.toString()\n  }\n\n  def bigIterator(start: BigInt, end: BigInt, step: BigInt = 1) =\n    Iterator.iterate(start)(_ + step).takeWhile(_ <= end)\n\n\n  def scanforPatternsInSha(dfShas: DataFrame, scanLength: Int, maxLength: Int): DataFrame = {\n    val scannedDf = SparkBinaryGenerator.generateScanLongColumns(dfShas, maxLength, scanLength)\n\n    val colsToExplode = (0 to maxLength - scanLength + 1).map(i => \"l\" + i).map(c => col(c))\n\n    val denormalizedDf = scannedDf.select('inputBinary, 'shaString, explode(array(colsToExplode: _*))\n      .as(\"patterns\"))\n\n    denormalizedDf.select(\"patterns\").distinct()\n  }\n\n  def loadTruthTable(n :Int) :DataFrame = {\n    spark.read.parquet(dataDir + \"/\" + n.toString + \"bitTruthTable\")\n  }\n}\n\n","user":"anonymous","dateUpdated":"2020-05-03T10:12:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","runOnSelectionChange":true,"title":false,"checkEmpty":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\u001b[33mwarning: \u001b[0mthere was one feature warning; for details, enable `:setting -feature' or `:replay -feature'\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions.{col, udf, _}\nimport scala.collection.immutable\nimport java.util\ndefined object BitSetUtils\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions.{col, udf, _}\nimport scala.collection.immutable\ndefined object SparkBinaryGenerator\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1588498179762_1471717724","id":"paragraph_1588498179762_1471717724","dateCreated":"2020-05-03T09:29:39+0000","dateStarted":"2020-05-03T10:12:16+0000","dateFinished":"2020-05-03T10:12:16+0000","status":"FINISHED","$$hashKey":"object:5511"},{"text":"def generateAndSaveTruthTable(n :Int) :Unit = {\n    val df = SparkBinaryGenerator.generateTruthTableString(n)\n    df.write.mode(SaveMode.Overwrite).parquet(dataDir + \"/\" + n.toString + \"bitTruthTable\")\n    println(\"finished \" + n)\n  }\n","user":"anonymous","dateUpdated":"2020-05-03T10:10:57+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","runOnSelectionChange":true,"title":false,"checkEmpty":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\u001b[1m\u001b[34mgenerateAndSaveTruthTable\u001b[0m: \u001b[1m\u001b[32m(n: Int)Unit\u001b[0m\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1588498183260_-528903323","id":"paragraph_1588498183260_-528903323","dateCreated":"2020-05-03T09:29:43+0000","dateStarted":"2020-05-03T10:10:57+0000","dateFinished":"2020-05-03T10:10:57+0000","status":"FINISHED","$$hashKey":"object:5512"},{"user":"anonymous","config":{"runOnSelectionChange":true,"title":false,"checkEmpty":true,"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1588501250717_-990830144","id":"paragraph_1588501250717_-990830144","dateCreated":"2020-05-03T10:20:50+0000","status":"READY","focus":true,"$$hashKey":"object:8791","text":"","dateUpdated":"2020-05-03T10:20:59+0000"},{"text":"    generateAndSaveTruthTable(13)\n    generateAndSaveTruthTable(14)\n    generateAndSaveTruthTable(15)\n    generateAndSaveTruthTable(16)\n    generateAndSaveTruthTable(17)\n    generateAndSaveTruthTable(18)\n    generateAndSaveTruthTable(19)\n    generateAndSaveTruthTable(20)\n    generateAndSaveTruthTable(21)\n    generateAndSaveTruthTable(22)\n    generateAndSaveTruthTable(23)\n    generateAndSaveTruthTable(24)\n    generateAndSaveTruthTable(25)\n    generateAndSaveTruthTable(26)\n    generateAndSaveTruthTable(27)\n    generateAndSaveTruthTable(28)\n    generateAndSaveTruthTable(29)\n    generateAndSaveTruthTable(30)\n    generateAndSaveTruthTable(31)\n    generateAndSaveTruthTable(32)","user":"anonymous","dateUpdated":"2020-05-03T10:12:22+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","runOnSelectionChange":true,"title":false,"checkEmpty":true},"settings":{"params":{},"forms":{}},"results":{"msg":[{"data":"","type":"TEXT"}]},"apps":[],"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":[{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=16","$$hashKey":"object:8868"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=17","$$hashKey":"object:8869"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=18","$$hashKey":"object:8870"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=19","$$hashKey":"object:8871"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=20","$$hashKey":"object:8872"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=21","$$hashKey":"object:8873"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=22","$$hashKey":"object:8874"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=23","$$hashKey":"object:8875"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=24","$$hashKey":"object:8876"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=25","$$hashKey":"object:8877"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=26","$$hashKey":"object:8878"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=27","$$hashKey":"object:8879"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=28","$$hashKey":"object:8880"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=29","$$hashKey":"object:8881"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=30","$$hashKey":"object:8882"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=31","$$hashKey":"object:8883"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=32","$$hashKey":"object:8884"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=33","$$hashKey":"object:8885"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=34","$$hashKey":"object:8886"},{"jobUrl":"http://ip-172-31-17-36.us-east-2.compute.internal:4040/jobs/job?id=35","$$hashKey":"object:8887"}],"interpreterSettingId":"spark"}},"progressUpdateIntervalMs":500,"jobName":"paragraph_1588498227684_-110424025","id":"paragraph_1588498227684_-110424025","dateCreated":"2020-05-03T09:30:27+0000","dateStarted":"2020-05-03T10:12:22+0000","dateFinished":"2020-05-03T10:12:01+0000","status":"RUNNING","$$hashKey":"object:5513"},{"text":"spark.sparkContext.defaultParallelism","user":"anonymous","dateUpdated":"2020-05-03T10:10:41+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","runOnSelectionChange":true,"title":false,"checkEmpty":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\u001b[1m\u001b[34mres3\u001b[0m: \u001b[1m\u001b[32mInt\u001b[0m = 16\n"}]},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1588499000484_1211659576","id":"paragraph_1588499000484_1211659576","dateCreated":"2020-05-03T09:43:20+0000","dateStarted":"2020-05-03T10:10:41+0000","dateFinished":"2020-05-03T10:10:41+0000","status":"FINISHED","$$hashKey":"object:5514"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"runtimeInfos":{},"progressUpdateIntervalMs":500,"jobName":"paragraph_1588500044429_405330848","id":"paragraph_1588500044429_405330848","dateCreated":"2020-05-03T10:00:44+0000","status":"READY","$$hashKey":"object:5515"}],"name":"Untitled Note 1","id":"2F7WD9JVG","defaultInterpreterGroup":"spark","version":"0.9.0-SNAPSHOT","permissions":{},"noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{},"path":"/Untitled Note 1"}